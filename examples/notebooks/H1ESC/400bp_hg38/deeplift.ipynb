{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import deeplift\n",
    "import evautils\n",
    "from evautils import sequtils\n",
    "from evautils import kerasutils\n",
    "from evautils import dirutils\n",
    "from evautils import impscoringutils\n",
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REGION_SIZE = 400\n",
    "CELL_LINE = 'H1ESC'\n",
    "POS_PREFIX = CELL_LINE +'_' + str(REGION_SIZE)\n",
    "MASTER_DIR='/users/eprakash/benchmarking/H1ESC/400bp_hg38'\n",
    "DL_BASE_DIR=MASTER_DIR+'/deeplift'\n",
    "PREPROCESSING_BASE_DIR = MASTER_DIR+'/preprocessing'\n",
    "TRAINING_BASE_DIR=MASTER_DIR+'/training'\n",
    "MOMMA_DRAGONN=TRAINING_BASE_DIR+'/'+'momma_dragonn'\n",
    "IMPLANTED_POS_BED_FILE = PREPROCESSING_BASE_DIR + '/' + 'implanted_' + POS_PREFIX + '.bed.gz'\n",
    "MODEL_PREFIX='record_1_model_XHjBt_'\n",
    "MODEL=MOMMA_DRAGONN+'/examples/fasta_sequential_model/model_files/'+MODEL_PREFIX+'modelJson.json'\n",
    "WEIGHTS=MOMMA_DRAGONN+'/examples/fasta_sequential_model/model_files/'+MODEL_PREFIX+'modelWeights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirutils.createDir(DL_BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loading /users/eprakash/benchmarking/H1ESC/400bp_hg38/preprocessing/implanted_H1ESC_400.bed.gz ...\n",
      "#Loaded 96663 sequences from /users/eprakash/benchmarking/H1ESC/400bp_hg38/preprocessing/implanted_H1ESC_400.bed.gz\n",
      "Got 96663 positive sequences\n",
      "Sequences length:  96663\n"
     ]
    }
   ],
   "source": [
    "data_filename_positive = IMPLANTED_POS_BED_FILE\n",
    "labeled_sequences = sequtils.load_sequences_from_bedfile(data_filename_positive)\n",
    "print(\"Got %d positive sequences\" % len(labeled_sequences))\n",
    "positive_labels = labeled_sequences.keys()\n",
    "labels = labeled_sequences.keys()\n",
    "sequences =labeled_sequences.values()\n",
    "print(\"Sequences length: \", len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96663\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNGAATTCTATCTGATGGCGTTGTCATTTTTGTGCGGTTTTTGTTTCCCGGTTGTGTTTTCGAGCGGCTGTATTGGATGGAATTGAGGGGTCTGCTAAGGTTGCTGCTTTTCTCTAGAGATTCTGGCTTTTAATGGGTGCAGCCGCTGTTTTTTTGTTGCTTCAGAGATGCGCATCGATGCCGCATTGGGGGCTAGAGCTTGCTCGGATTGTTTCCTGTAGCTGCCTATTCCGGATGCGTTTGCTTGTGGCGATCTCGTTTTCCAATCAGGCAGGGGAAAGGTTTTCCAGAGGAAAAGGTTGTTGCCAGTGGATTTGGTTCCGTTCGGTGCGTTGTTCTGGCTAGGTGGGGGGAGGGGCTGTCCCGTG\n",
      "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNGAATTCCTGCTGAAGGCACGCGCGTTGCCAGGCAATAGCTTCTTGGAGGGGCGCCCCTCTACTGCGCATGTGCGGGTTTCCAGGCAGGGATCGGTCGTTCTCCTCTAGCCCAGGCGGAGCTCTGTCACGTTTTTCCCCGCGTTCGGTCTTCGGGTTGGCGGTCCCAACACACCGCGAAACAAGCCGGCCCAGGATTTCTCCCATGTCAGGGCCTTTCTGCGGCTAGTGAGCCCACTCTCTTCGCCCGTGGTCCAGTAGGCTTCCCACCCTTGAGAGGGCTCTT\n",
      "TATGTAGTAACTCCTATATACCATTAATATATATATAATATGTCCATTGTATCATAACCTGTATGTAAATCTATTAACAACCATCTATAAATGAGTAATGTACCATGTAAGTCAGTAGTGTGTAATAAAAGACTAAACTAATATACAGTACAACAACAAATATACAGAGTAAATAAAAATTCAATAACCCAATATATGTGAATAATAGTACTGTTATACCCAATAAATTACAATAAAAACCCATATGCCACATAAAGTATATGATACCATCAAAAGTTAAGTAAGTAACTTAATATGTAATCNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "96660\n",
      "dinuc_shuffled_motifs_implanted_chr18:47019878-47020278\n",
      "dinuc_shuffled_motifs_implanted_chr20:30811781-30812181\n",
      "dinuc_shuffled_motifs_implanted_chr4:51107277-51107677\n",
      "96660\n",
      "96660\n"
     ]
    }
   ],
   "source": [
    "sequtils.removeUnsupportedChars(sequences, labels, labeled_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96660, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "onehot_data = np.array([sequtils.one_hot_encode_along_channel_axis(seq) for seq in sequences])\n",
    "print(onehot_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Keras JSON model from file /users/eprakash/benchmarking/H1ESC/400bp_hg38/training/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_XHjBt_modelJson.json\n",
      "Loading Keras model weights from file /users/eprakash/benchmarking/H1ESC/400bp_hg38/training/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_XHjBt_modelWeights.h5\n",
      "Successfully loaded\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 393, 320)          10560     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 393, 320)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 386, 320)          819520    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 386, 320)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 386, 320)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 96, 320)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 89, 480)           1229280   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 89, 480)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 82, 480)           1843680   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 82, 480)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 82, 480)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 20, 480)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 13, 640)           2458240   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 640)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 6, 640)            3277440   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 6, 640)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2003)              7693523   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2003)              0         \n",
      "_________________________________________________________________\n",
      "newdense (Dense)             (None, 1)                 2004      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,334,247\n",
      "Trainable params: 17,334,247\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model=kerasutils.load_keras_model_using_json(MODEL, WEIGHTS)\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96660, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = keras_model.predict(onehot_data)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96660\n",
      "96660\n"
     ]
    }
   ],
   "source": [
    "top_1k_pos_labels, top_pos_seqs=kerasutils.getTopNumPos(labels, labeled_sequences, preds, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File(DL_BASE_DIR+'/'+POS_PREFIX+'_top_1k_pos_labels.h5', 'w')\n",
    "h5f.create_dataset('labels', data=top_1k_pos_labels)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: DeepLIFT_GenomicsDefault\n",
      "For layer 1 the preceding linear layer is 0 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 3 the preceding linear layer is 2 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 7 the preceding linear layer is 6 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 9 the preceding linear layer is 8 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 13 the preceding linear layer is 12 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 15 the preceding linear layer is 14 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 18 the preceding linear layer is 17 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "For layer 20 the preceding linear layer is 19 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "nonlinear_mxts_mode is set to: Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "nonlinear_mxts_mode is set to: RevealCancel\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "nonlinear_mxts_mode is set to: Gradient\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "nonlinear_mxts_mode is set to: GuidedBackprop\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n"
     ]
    }
   ],
   "source": [
    "method_to_model=kerasutils.prepareDLModel(WEIGHTS, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('maximum difference in predictions:', 0.0)\n"
     ]
    }
   ],
   "source": [
    "#make sure predictions are the same as the original model\n",
    "from deeplift.util import compile_func\n",
    "model_to_test = method_to_model['rescale_conv_revealcancel_fc']\n",
    "kerasutils.sanityCheck(model_to_test, onehot_data, keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling scoring functions\n",
      "Compiling scoring function for: rescale_conv_revealcancel_fc\n",
      "Compiling scoring function for: rescale_all_layers\n",
      "Compiling scoring function for: revealcancel_all_layers\n",
      "Compiling scoring function for: grad_times_inp\n",
      "Compiling scoring function for: guided_backprop\n",
      "Compiling integrated gradients scoring functions\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "method_to_scoring_func = impscoringutils.compileScoringFunctions(method_to_model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"labels\": shape (96660,), type \"|S57\">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_to_task_to_scores = OrderedDict()\n",
    "all_zeroes_methods=['grad_times_inp', 'rescale_all_layers']\n",
    "avg_gc_methods=['rescale_all_layers']\n",
    "multiref_methods=['rescale_all_layers', 'rescale_conv_revealcancel_fc']\n",
    "ig=['integrated_gradients10']\n",
    "h5f = h5py.File(DL_BASE_DIR+'/'+POS_PREFIX+'_dl_scores.h5', 'w')\n",
    "h5f.create_dataset(\"labels\", data=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rescale_conv_revealcancel_fc', 'rescale_all_layers', 'revealcancel_all_layers', 'grad_times_inp', 'guided_backprop', 'integrated_gradients10']\n",
      "('on method', 'rescale_conv_revealcancel_fc')\n",
      "('scorefunc ', <function func at 0x7f3b94416488>)\n",
      "('on method', 'rescale_all_layers')\n",
      "('scorefunc ', <function func at 0x7f3b94416e60>)\n",
      "('on method', 'revealcancel_all_layers')\n",
      "('scorefunc ', <function func at 0x7f3b8d73af50>)\n",
      "('on method', 'grad_times_inp')\n",
      "('scorefunc ', <function func at 0x7f3b8ce04140>)\n",
      "('on method', 'guided_backprop')\n",
      "('scorefunc ', <function func at 0x7f3b8c69a938>)\n",
      "('on method', 'integrated_gradients10')\n",
      "('scorefunc ', <function compute_integrated_gradients at 0x7f3b7bf8e050>)\n",
      "On method variation: integrated_gradients10_all_zeros_ref\n",
      "Done!\n",
      "Storing scores for integrated_gradients10_all_zeros_ref\n"
     ]
    }
   ],
   "source": [
    "impscoringutils.flatRefScore(method_to_task_to_scores, method_to_scoring_func, ig, onehot_data, 0)\n",
    "print(\"Done!\")\n",
    "for meth in method_to_task_to_scores.keys():\n",
    "    print(\"Storing scores for \" + str(meth))\n",
    "    h5f.create_dataset(meth, data=method_to_task_to_scores[meth][0])\n",
    "method_to_task_to_scores.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rescale_conv_revealcancel_fc', 'rescale_all_layers', 'revealcancel_all_layers', 'grad_times_inp', 'guided_backprop', 'integrated_gradients10']\n",
      "('on method', 'rescale_conv_revealcancel_fc')\n",
      "('scorefunc ', <function func at 0x7f3b94416488>)\n",
      "('on method', 'rescale_all_layers')\n",
      "('scorefunc ', <function func at 0x7f3b94416e60>)\n",
      "On method variation: rescale_all_layers_all_zeros_ref\n",
      "('on method', 'revealcancel_all_layers')\n",
      "('scorefunc ', <function func at 0x7f3b8d73af50>)\n",
      "('on method', 'grad_times_inp')\n",
      "('scorefunc ', <function func at 0x7f3b8ce04140>)\n",
      "On method variation: grad_times_inp_all_zeros_ref\n",
      "('on method', 'guided_backprop')\n",
      "('scorefunc ', <function func at 0x7f3b8c69a938>)\n",
      "('on method', 'integrated_gradients10')\n",
      "('scorefunc ', <function compute_integrated_gradients at 0x7f3b7bf8e050>)\n",
      "Done!\n",
      "Storing scores for rescale_all_layers_all_zeros_ref\n",
      "Storing scores for grad_times_inp_all_zeros_ref\n"
     ]
    }
   ],
   "source": [
    "impscoringutils.flatRefScore(method_to_task_to_scores, method_to_scoring_func, all_zeroes_methods, onehot_data, 0)\n",
    "print(\"Done!\")\n",
    "for meth in method_to_task_to_scores.keys():\n",
    "    print(\"Storing scores for \" + str(meth))\n",
    "    h5f.create_dataset(meth, data=method_to_task_to_scores[meth][0])\n",
    "method_to_task_to_scores.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2195576  0.28032617 0.28106109 0.21905514]\n",
      "OrderedDict([('A', 0.21955759879991724), ('C', 0.2803261690461411), ('G', 0.28106109042002897), ('T', 0.2190551417339127)])\n",
      "['rescale_conv_revealcancel_fc', 'rescale_all_layers', 'revealcancel_all_layers', 'grad_times_inp', 'guided_backprop', 'integrated_gradients10']\n",
      "('on method', 'rescale_conv_revealcancel_fc')\n",
      "('scorefunc ', <function func at 0x7f3b94416488>)\n",
      "('on method', 'rescale_all_layers')\n",
      "('scorefunc ', <function func at 0x7f3b94416e60>)\n",
      "('on method', 'revealcancel_all_layers')\n",
      "('scorefunc ', <function func at 0x7f3b8d73af50>)\n",
      "('on method', 'grad_times_inp')\n",
      "('scorefunc ', <function func at 0x7f3b8ce04140>)\n",
      "('on method', 'guided_backprop')\n",
      "('scorefunc ', <function func at 0x7f3b8c69a938>)\n",
      "('on method', 'integrated_gradients10')\n",
      "('scorefunc ', <function compute_integrated_gradients at 0x7f3b7bf8e050>)\n",
      "On method variation: integrated_gradients10_avg_gc_ref\n"
     ]
    }
   ],
   "source": [
    "impscoringutils.flatRefScore(method_to_task_to_scores, method_to_scoring_func, ig, onehot_data, 1)\n",
    "print(\"Done!\")\n",
    "for meth in method_to_task_to_scores.keys():\n",
    "    print(\"Storing scores for \" + str(meth))\n",
    "    h5f.create_dataset(meth, data=method_to_task_to_scores[meth][0])\n",
    "method_to_task_to_scores.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impscoringutils.flatRefScore(method_to_task_to_scores, method_to_scoring_func, avg_gc_methods, onehot_data, 1)\n",
    "print(\"Done!\")\n",
    "for meth in method_to_task_to_scores.keys():\n",
    "    print(\"Storing scores for \" + str(meth))\n",
    "    h5f.create_dataset(meth, data=method_to_task_to_scores[meth][0])\n",
    "method_to_task_to_scores.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impscoringutils.multirefScore(method_to_task_to_scores, method_to_scoring_func, ig, top_pos_seqs)\n",
    "print(\"Done!\")\n",
    "for meth in method_to_task_to_scores.keys():\n",
    "    print(\"Storing scores for \" + str(meth))\n",
    "    h5f.create_dataset(meth, data=method_to_task_to_scores[meth][0])\n",
    "method_to_task_to_scores.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impscoringutils.multirefScore(method_to_task_to_scores, method_to_scoring_func, multiref_methods, sequences)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for meth in method_to_task_to_scores.keys():\n",
    "    print(\"Storing scores for \" + str(meth))\n",
    "    h5f.create_dataset(meth, data=method_to_task_to_scores[meth][0])\n",
    "method_to_task_to_scores.clear()\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
